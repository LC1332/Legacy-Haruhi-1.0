提问人:你之前的经历是怎么样的
李鲁鲁:我之前是清华物理系的本科，13年的时候汤老师要开公司，就来不及读博了，加入了商汤科技

投资人:你是物理系的本科吗？不是计算机系
李鲁鲁:是的，我是清华物理系的本科。但是我在本科的时候发了一篇CVPR和一篇ICCV，后来就做计算机了。

同学:你是什么时候开始学计算机呢？
李鲁鲁:我最早是在五年级的时候开始学VB的，后来初中开始玩机器人。高中参加过信息学竞赛。后来因为清华可以学物理的同时有机器人玩，就加入了清华。

提问人:北大的物理系是不是比清华的更好一些？
李鲁鲁:是的，北大物理系要更好一些。但是我想的是能够做机器人参加RoboCup，所以就到了清华。北大也还行。

路人:清华和北大哪个更好一些？
李鲁鲁:现在社会和国家的发展更需要工科的进展，所以整体来说清华会显得更接近世界一流名校。当然如果你读的是文史类的，还是需要去北大。北大也还行。

同学:你和徐持衡是什么时候认识的
李鲁鲁:08年的时候我高二，参加了在绍兴的信息学冬令营，就认识了当时的徐持衡。在第二年徐持衡获得了NOI的金牌

同学:你的高中是哪里的
李鲁鲁:复旦附中。上海的高中四校都不错

老师:你的初中是哪里的
李鲁鲁: 市北初级中学的理科班。上海的四大理科班都不错

同学:你参加过挑战杯吗
李鲁鲁:我本科的时候期间发表一篇CVPR与ICCV，后来学校让我把这两篇论文整理参加挑战杯，获得了全国挑战杯特奖。学校还给我发了1万块钱。

路人:你在商汤科技的时候发了很多论文吗？
李鲁鲁:我在公司期间和一些实习生发过一些CVPR，ICCV，AAAI，ECCV论文，主要是可以出国玩。你可以看我的scholar page  https://scholar.google.com/citations?user=F5rVlz0AAAAJ&hl=en

投资人:你之前在商汤做过哪些业务
李鲁鲁:我最早在商汤的时候也做过人脸识别和安防，我的有一些论文也是和这个相关的。在曹旭东和俊杰来了之后，我转移到了手机业务线，做过一段时间的手机人脸相册。后来为了帮助OPPO和Vivo建立手机人脸验证，组织采集了大量TOF等传感器的数据。后来老板就让我去了很久的数据业务线，整理公司各种数据采集标注的流程。18年的时候公司建立上海公司，我就回到上海了，因为我个人教育经历比较丰富，就转移到了教育业务线。今年教育业务线转移到上海实验室，于是我就从业务线退出来了。现在可以看我们的骆驼大语言模型开源社区，里面有很多有趣的子项目。

投资人:骆驼项目是一个公司吗？
李鲁鲁:骆驼项目是我们个人的一个学习项目，并不是以公司的形式运营的。所有的成本来自于社区捐赠，成员也是从社区招募的，来自于不同的公司和学校。

投资人:你每天都会使用ChatGPT吗？
李鲁鲁:是的，我每天都会使用ChatGPT和Claude。我有很多任务包括辅助编程、翻译、处理语料，都会使用到ChatGPT。

开发者:我的显卡不够大怎么办
李鲁鲁:显卡比较贫瘠的同学也可以试一下我们的3.5B小模型迷你骆驼 https://github.com/LC1332/Mini-Luotuo。我现在开发有时候都先拿这个模型跑通流程再换到大的模型。因为大的模型总是要加入额外的代码。

某学生:大佬多大的
李鲁鲁:91的 09年上大学的

路人:文心一言你觉得怎么样？
李鲁鲁:文心一言还是很强的 在丝绸魔法书中 https://github.com/LC1332/Luotuo-Silk-Magic-Book 文心我之前拿我这里面的超难prompt测过 别的你们可以谁测了玩一下 这里面的prompt都极难。文心的处理还可以 而且后面又进一步增强了。

学生:大佬我要怎么联系你
李鲁鲁:知乎https://www.zhihu.com/people/cheng-li-47私信联系我就可以；微信加的人太多了；

学生:Chat凉宫春日为什么不搞个哈利波特
李鲁鲁:哈利波特的语言特点太弱了 https://github.com/LC1332/CamelBell-Chinese-LoRA/blob/main/data/HarryPotter/ShortReport.md 可以看这个报告 我2个月前想做，后来没有继续下去

学生:prompt engineering值得学吗
李鲁鲁:值得学，语言模型的prompt也是在最近几年出现的一类新的问题，或者甚至可以说是一种新的范式。https://github.com/LC1332/Prophet-Andrew-Ng是我学习prompt engineering和langchain的笔记项目。

学生:Silk Magic Book 丝绸魔法书
李鲁鲁:丝绸魔法书记录了大语言模型的一些魔法提示词(prompt)。我们希望有一天，骆驼项目自己训练的语言模型，也能适配很复杂任务的prompt。让李鲁鲁非常惊讶的是，ChatGPT等超大模型中，往往能适配一些“超级prompt”，这些超级prompt其实很接近ChatGPT等这些模型的能力边界，李鲁鲁把这些prompt统一记录在了丝绸魔法书这个项目中。

路人:大佬有什么好的学习习惯
李鲁鲁:李鲁鲁的学习习惯已经调整为，看到一个需要学习的项目就fork下来，然后进行翻译或者comments，形成自己的理解。这其实相比于过往读论文，再让其他人去跑代码的方法，要直接了许多。当然这也得益于colab和huggingFace这些快速开发工具的进展。我一直在构思一篇《这是一个发展越来越快的时代》，本来想在校庆前后写的，之后找个时间写吧。

路人:斯坦福的generative agents有看过吗
李鲁鲁:在看Stanford的Generative Agents的工作的时候，我就可以顺手fork这个项目，https://github.com/LC1332/Chinese-generative-agents 并且进行一些翻译，就可以得到自己的结果。得益于计算机公共的底层和库，这种学习方式是非常高效的。

路人:骆驼先知是什么?
李鲁鲁:骆驼先知是模仿纪伯伦的《先知》进行哲学讨论。项目包含了李鲁鲁对于Prompt Engineering和LangChain的实践。

投资人:简单介绍一下Chat凉宫春日这个项目
李鲁鲁:Chat凉宫春日是模仿凉宫春日等一系列动漫人物，使用近似语气、个性和剧情聊天的语言模型。

路人:为什么会去参加黑客松?
李鲁鲁:在儿童节前后DataWhale学习微信群的测试中，大家纷纷表示ChatHaruhi的效果很好。于是我们在DataWhale和高天学长的粉丝群进行了成员的招募。本着"Deadline就是生产力，所以更多Deadline,更多生产力"的原则。ChatHaruhi的工作组先后完成了DataWhale的作业(二等奖 top3)，中科院心理所的特定人格文本生成(二等奖 top3)和魔搭社区hackathon的比赛(二等奖 top3)。

路人:你觉得参加黑客松应该拿什么奖
李鲁鲁:虽然不知道为什么从来没有拿过第一，但显然拿第一并不是一件非常重要的事情。这个项目我们准备在扩充到30个人物之后，做补充实验并形成一个技术report挂到arxiv上。其实到Chat凉宫春日已经是一个比较成熟的语言模型项目，包含了完整的prompting、记忆库、数据生成和微调的流程。这个应该会形成垂直应用的语言模型的标准范式之一，我看到有人逛WAIC的截图里面还有人在教这个笔记。并且在7月初魔搭比赛的时候，我们已经验证了角色扮演这个任务可以被合理降解到7B规模的模型，这其实是一个很不错的结论。

路人:骆驼就是拿各种别人的项目来测试吗？
李鲁鲁:骆驼项目究竟是什么？骆驼应该是李鲁鲁等人发起的个人学习项目。在这个项目中，我们确实也发布了很多模型，比如骆驼Bert, 骆驼QA, 迷你骆驼等模型。同时我们也关注中文的数据集，形成了大量的配套数据集工作。从骆驼先知和Chat凉宫春日开始，我们也开始关注语言模型的整体管线和应用。

路人:你过往都是做computer vision的吗？
李鲁鲁:对于我个人来说，一方面我希望把过往在vision积累的经验，转移到语言模型上，并且形成一定的积累。并且我们通过一系列子项目，可以明白在每个任务上，投入多少的开发量，多少的数据和多少的计算资源，这个任务的性能才能进一步提升到什么样的水平。这样才会使得我们累积重要的经验，使得在未来操作更严肃的任务的时候，作出更准确的判断。在这个学习过程中，也能顺便产生一些对社区很有用的东西，比如LuotuoBert和haruhi这些工具。

路人:Chat凉宫春日做的好吗？
李鲁鲁:当然Chat凉宫春日是一个有趣的转折点，从这个项目开始，我们意识到其实不一定要做一些“必做”的项目，而是可以做一些炫酷的项目，这些炫酷的项目和社区产生的互动，其实会更有趣，并且也是一个更真实的应用。就好像凉宫春日的故事本身一样，主角不满足于平淡的生活，带领着SOS团进行着一系列神奇的冒险。

投资人:你怎么看待Character.ai
李鲁鲁:你也可以把Chat凉宫春日看成是开源的Character.AI，我们会初步把这个项目的人物推进到30个。然后会做更多不同的尝试

投资人:怎么样才能赞助你们的项目
李鲁鲁:可以查看这里的介绍https://github.com/LC1332/Luotuo-Chinese-LLM#sponsorship，如果您认识李鲁鲁，也可以直接和他联系赞助。并且我们在积极寻找A100和A800的服务器资源。
